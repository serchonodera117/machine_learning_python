# -*- coding: utf-8 -*-
"""clasifier_knife_spoon_fork.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XCEEN1PfYFKZMHHVp-qtVL2zv--WrbJ0
"""

!mkdir cuchillos
!mkdir cucharas
!mkdir tenedores

# Commented out IPython magic to ensure Python compatibility.
#entrar en cada carpeta y descomprimir el archivo zip

# %cd cuchillos
!unzip cuchillos.zip

# %cd ../cucharas
!unzip cuchara.zip

# %cd ../tenedores
!unzip tenedores.zip

# %cd ..

!rm -rf /content/cucharas/cuchara.zip
!rm -rf /content/cuchillos/cuchillos.zip
!rm -rf /content/tenedores/tenedores.zip

!ls /content/cucharas/cuchara | wc -l #349
!ls /content/cuchillos/cuchillos | wc -l #306
!ls /content/tenedores/tenedores | wc -l #308

#mostrar imagenes con pyplot
import os
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

plt.figure(figsize=(15,15))

carpeta = '/content/cuchillos/cuchillos'
images = os.listdir(carpeta)

for i, nombreimg in enumerate(images[:25]):
  plt.subplot(5,5, i+1)
  imagen = mpimg.imread(carpeta + '/' + nombreimg)
  plt.imshow(imagen)

#crear carpetas para hacer el set de datos
!mkdir dataset
!mkdir dataset/cuchillos
!mkdir dataset/tenedores
!mkdir dataset/cuchara

#copiar imagenes de las carpetas al dataset
#limitar para que todos tengan la misma cantidad de imagenes
#306 el numero menor de imagenes que sbuni

import shutil
carpeta_fuente_cuchillo = '/content/cuchillos/cuchillos'
carpeta_destino_cuchillo = '/content/dataset/cuchillos'

carpeta_fuente_cuchara = '/content/cucharas/cuchara'
carpeta_destino_cuchara = '/content/dataset/cuchara'

carpeta_fuente_tenedor = '/content/tenedores/tenedores'
carpeta_destino_tenedor = '/content/dataset/tenedores'

imagenes = os.listdir(carpeta_fuente_cuchillo)
imagenes_cuchara = os.listdir(carpeta_fuente_cuchara)
imagenes_tenedor = os.listdir(carpeta_fuente_tenedor)

for i, nombreimg in enumerate(imagenes):
  if i < 306:
    shutil.copy(carpeta_fuente_cuchillo + '/' + nombreimg , carpeta_destino_cuchillo + '/' + nombreimg)

for i, nombreimg in enumerate(imagenes_cuchara):
  if i < 306:
    shutil.copy(carpeta_fuente_cuchara + '/' + nombreimg , carpeta_destino_cuchara + '/' + nombreimg)

for i, nombreimg in enumerate(imagenes_tenedor):
  if i < 306:
    shutil.copy(carpeta_fuente_tenedor + '/' + nombreimg , carpeta_destino_tenedor + '/' + nombreimg )

!ls /content/dataset/cuchara | wc -l
!ls /content/dataset/cuchillos | wc -l
!ls /content/dataset/tenedores | wc -l

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np

#creación del dataset generador
datagen = ImageDataGenerator(
    rescale = 1. / 255,
    rotation_range = 30,
    width_shift_range = 0.25,
    height_shift_range = 0.25,
    shear_range = 15,
    zoom_range = [0.5, 1.5],
    validation_split   = 0.2 # para pruebas
)

#generador de sets de entrenamiento y pruebas
data_gen_entrenamiento = datagen.flow_from_directory(
    '/content/dataset',
    target_size=(224, 224,),
    batch_size = 32, shuffle=True,
    subset='training'
)
data_gen_pruebas = datagen.flow_from_directory(
    '/content/dataset',
    target_size=(224, 224,),
    batch_size = 32, shuffle=True,
    subset='validation'
)

#imprimir 10 imagenes del generador de entrenamiento
for imagen, etiqueta in data_gen_entrenamiento:
  for i in range(10):
    plt.subplot(2,5, i+1)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(imagen[i])
  break
plt.show()

import tensorflow as tf
import tensorflow_hub as hubtf

url = "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4"
mobilenetv2 = hubtf.KerasLayer(url, input_shape=(224, 224, 3))

#congelar parámetros para un mejor entrenamiento, ya que se pondrán mis propios parámetros de entrenamiento con el arduo trabajo que hizo google
mobilenetv2.trainable = False

modelo = tf.keras.Sequential([
    mobilenetv2,
    tf.keras.layers.Dense(3, activation='softmax')
])

modelo.summary()

#complar modelo
modelo.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

#entrenamiento
Epocas = 50

historial = modelo.fit(
    data_gen_entrenamiento, epochs = Epocas, batch_size = 32,
    validation_data= data_gen_pruebas
)

#graficas de presición
acc = historial.history['accuracy']
val_acc = historial.history['val_accuracy']

loss = historial.history['loss']
val_loss = historial.history['val_loss']

rango_epocas = range(50)

plt.figure(figsize=(8,8))
plt.subplot(1,2,1)
plt.plot(rango_epocas, acc, label='Presicion entrenamiento')
plt.plot(rango_epocas, val_acc, label='Presicion pruebas')

plt.subplot(1,2,2)
plt.plot(rango_epocas, loss, label="perdida de entrenamiento")
plt.plot(rango_epocas, val_loss, label="perdida de pruebas")
plt.legend(loc='upper right')
plt.title('perdida de entrenamiento y pruebas')
plt.show()

from PIL import Image
import requests
from io import BytesIO
import cv2

def categorizar(url):
  respuesta = requests.get(url)
  img = Image.open(BytesIO(respuesta.content))
  img = np.array(img).astype(float)/255  #normalizar

  img = cv2.resize(img, (224, 224))
  reshapedImg = img.reshape(-1, 224, 224, 3)
  prediccion = modelo.predict(reshapedImg)
  return np.argmax(prediccion[0], axis=-1)

#0 = cuchara, 1 cuchillo, 2=tenedor

url = "https://www.vianca.mx/wp-content/uploads/2021/02/203046_prod-Cuchillo-chef-12.jpg"
prediccion = categorizar(url)
print(prediccion)